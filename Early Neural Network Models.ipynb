{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO2lMmp0e7yGkIyvFIkPkRc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFcZy95N-cc-","executionInfo":{"status":"ok","timestamp":1730133479859,"user_tz":-300,"elapsed":985,"user":{"displayName":"Nimra Akhtar","userId":"14057954014391029517"}},"outputId":"989a753b-11b9-4228-8082-12a5b793b6be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Perceptron Predictions (AND Gate):\n","Input: [0 0], Prediction: 0\n","Input: [0 1], Prediction: 0\n","Input: [1 0], Prediction: 0\n","Input: [1 1], Prediction: 1\n","\n","MLP Predictions (XOR Gate):\n","Input: [0 0], Prediction: 0.035\n","Input: [0 1], Prediction: 0.960\n","Input: [1 0], Prediction: 0.958\n","Input: [1 1], Prediction: 0.044\n","\n","Hopfield Network Prediction (Pattern Recovery):\n","Test Pattern: [ 1 -1 -1 -1]\n","Recovered Pattern: [ 1. -1.  1. -1.]\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# 1. Perceptron Model\n","class Perceptron:\n","    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n","        self.weights = np.zeros(input_size + 1)  # Including bias\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","\n","    def activation(self, x):\n","        return 1 if x >= 0 else 0\n","\n","    def predict(self, x):\n","        summation = np.dot(x, self.weights[1:]) + self.weights[0]\n","        return self.activation(summation)\n","\n","    def train(self, X, y):\n","        for _ in range(self.epochs):\n","            for inputs, label in zip(X, y):\n","                prediction = self.predict(inputs)\n","                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n","                self.weights[0] += self.learning_rate * (label - prediction)\n","\n","# Training Perceptron\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([0, 0, 0, 1])  # AND operation\n","perceptron = Perceptron(input_size=2)\n","perceptron.train(X, y)\n","\n","print(\"Perceptron Predictions (AND Gate):\")\n","for inputs in X:\n","    print(f\"Input: {inputs}, Prediction: {perceptron.predict(inputs)}\")\n","\n","# 2. Multi-Layer Perceptron (MLP) with Backpropagation\n","class MLP:\n","    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1, epochs=10000):\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","\n","        # Initialize weights\n","        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n","        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n","        self.bias_hidden = np.zeros(hidden_size)\n","        self.bias_output = np.zeros(output_size)\n","\n","    def sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    def sigmoid_derivative(self, x):\n","        return x * (1 - x)\n","\n","    def feedforward(self, X):\n","        # Forward pass\n","        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n","        self.hidden_output = self.sigmoid(self.hidden_input)\n","        self.final_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n","        self.final_output = self.sigmoid(self.final_input)\n","        return self.final_output\n","\n","    def backpropagate(self, X, y, output):\n","        # Backward pass\n","        output_error = y - output\n","        output_delta = output_error * self.sigmoid_derivative(output)\n","\n","        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n","        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)\n","\n","        # Update weights and biases\n","        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * self.learning_rate\n","        self.weights_input_hidden += X.T.dot(hidden_delta) * self.learning_rate\n","        self.bias_output += np.sum(output_delta, axis=0) * self.learning_rate\n","        self.bias_hidden += np.sum(hidden_delta, axis=0) * self.learning_rate\n","\n","    def train(self, X, y):\n","        for _ in range(self.epochs):\n","            output = self.feedforward(X)\n","            self.backpropagate(X, y, output)\n","\n","# Training MLP\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([[0], [1], [1], [0]])  # XOR operation\n","mlp = MLP(input_size=2, hidden_size=4, output_size=1)\n","mlp.train(X, y)\n","\n","print(\"\\nMLP Predictions (XOR Gate):\")\n","for inputs in X:\n","    print(f\"Input: {inputs}, Prediction: {mlp.feedforward(inputs)[0]:.3f}\")\n","\n","# 3. Hopfield Network\n","class HopfieldNetwork:\n","    def __init__(self, num_neurons):\n","        self.num_neurons = num_neurons\n","        self.weights = np.zeros((num_neurons, num_neurons))\n","\n","    def train(self, patterns):\n","        # Train using Hebbian learning\n","        for p in patterns:\n","            self.weights += np.outer(p, p)\n","        np.fill_diagonal(self.weights, 0)\n","\n","    def predict(self, pattern, steps=10):\n","        # Update neurons synchronously\n","        output = pattern.copy()\n","        for _ in range(steps):\n","            output = np.sign(self.weights.dot(output))\n","        return output\n","\n","# Training Hopfield Network\n","patterns = np.array([[1, -1, 1, -1], [-1, 1, -1, 1]])  # Memorize two patterns\n","hopfield_net = HopfieldNetwork(num_neurons=4)\n","hopfield_net.train(patterns)\n","\n","# Testing Hopfield Network with noisy input\n","test_pattern = np.array([1, -1, -1, -1])  # Slightly noisy pattern\n","output_pattern = hopfield_net.predict(test_pattern)\n","\n","print(\"\\nHopfield Network Prediction (Pattern Recovery):\")\n","print(f\"Test Pattern: {test_pattern}\")\n","print(f\"Recovered Pattern: {output_pattern}\")\n"]}]}